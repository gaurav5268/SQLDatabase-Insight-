# Natural Language Database Insights Project 

project demo - https://naturallanguage-sqldatabase-insight.streamlit.app/

A database insights and analytics project that allows users to explore and analyze structured database records using natural-language queries.

The system is designed to work with relational databases. SQLite is used only as a lightweight deployment database for portability and easy execution.

The application is later integrated with a Streamlit + LLM powered pipeline to automatically generate SQL queries, insights, tables, and visual charts from user queries.

The project includes:

âœ” Natural Language â†’ SQL Query Generation  
âœ” Schema-Aware Database Understanding  
âœ” Relational Dataset with Foreign-Key Mapping  
âœ” Clean CSV-Based Data Import Pipeline  
âœ” Automatic Database Build & Rebuild Support  
âœ” Backend Dataset for Insight & Analytics System  

---

## Problem Statement

Database exploration normally requires writing SQL queries manually, understanding table relationships, validating foreign-key constraints, and handling structured dataset imports. For learners, analysts, and non-technical users this becomes complex and time-consuming.

This project solves that by:

- Preparing a clean and structured relational dataset  
- Loading data in dependency-safe order  
- Preserving referential integrity  
- Enabling natural-language driven database insights  

The database serves as a backend for:

ðŸŸ¢ SQL learning and practice  
ðŸŸ¢ Data analytics and reporting  
ðŸŸ¢ Natural-language query understanding  

---

## Dataset

The dataset is stored in CSV format and imported into the database.

Tables included:

employee â€” Employee personal and demographic details  
department â€” Department master data  
dept_emp â€” Employeeâ€“Department mapping  
title â€” Employee role and designation  
salary â€” Salary records  

The import process maintains relational consistency and foreign-key safety.

---

## Database Processing Pipeline

Step 1 â€” Create tables from schema  
Step 2 â€” Load data from CSV files  
Step 3 â€” Normalize and clean column headers  
Step 4 â€” Insert data in dependency-safe order  
Step 5 â€” Validate relational constraints  
Step 6 â€” Finalize database for analytics use  

This ensures:

âœ” No partial or corrupt imports  
âœ” No broken relationships  
âœ” Consistent and reproducible dataset  

---

## Business & Learning Objectives

This project is designed for:

âœ” Understanding relational database concepts  
âœ” Practicing SQL and analytical queries  
âœ” Hands-on data engineering workflow  
âœ” Backend dataset for insight applications  
âœ” Natural-language database exploration  

Example natural-language queries supported:

- Show employees working in Finance department  
- List salaries of Senior Engineers  
- Department-wise employee distribution  
- Generate chart of employees by title  

The system converts user queries to SQL and fetches insights automatically.

---

## Tech Stack

Languages â€” Python  
Database Runtime â€” SQLite (deployment convenience only; design is database-agnostic)  
Libraries â€” Pandas  
Data Source â€” CSV + Schema SQL  
Application Usage â€” Text-to-SQL Analytics Backend  

---

## Project Architecture

data/  
 â”œâ”€â”€ schema.sql  
 â”œâ”€â”€ employee.csv  
 â”œâ”€â”€ department.csv  
 â”œâ”€â”€ dept_emp.csv  
 â”œâ”€â”€ title.csv  
 â””â”€â”€ salary.csv  

.env  
app.py  
main.py  
prompts.py  

build_database.py  
database.db  

requirements.txt  
README.md  

---

## Installation & Setup

1) Install dependencies

pip install pandas

2) Run the database build script

python build_database.py

A clean database is generated:

database.db

Existing database is automatically deleted and rebuilt to ensure consistency and reproducibility.

---

## Key Highlights

âœ” Designed for database-centric learning and insights  
âœ” Clean relational dataset for analytics projects  
âœ” Automatic rebuild mechanism  
âœ” Suitable for LLM + Streamlit-based systems  
âœ” Lightweight runtime storage backend  

---

Gaurav Chauhan
